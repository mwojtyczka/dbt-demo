version: 2

models:
  - name: my_python_model

    # Document within the same codebase
    description: My transformation written in Python

    # Configure in ways that feel intuitive and familiar
    config:
      materialized: table
      tags: ['python']

      # Define cluster to execute the model if not defined elsewhere (e.g. inside dbt_project.yml or within code).
      # https://docs.getdbt.com/docs/build/python-models#specific-data-platforms
      #submission_method: all_purpose_cluster # using all-purpose (interactive) cluster to execute the python models
      #create_notebook: False
      #cluster_id: 0709-132523-cnhxf2p6
#      # run the python models using job cluster (new cluster for every dbt run)
#      submission_method: job_cluster
#      job_cluster_config:
#        # https://docs.databricks.com/api/workspace/jobs/create#job_clusters-new_cluster
#        spark_version: 13.3.x-scala2.12
#        node_type_id: i3.xlarge
#        data_security_mode: SINGLE_USER
#        num_workers: 0
#        spark_conf:
#          spark.master: "local[*, 4]"
#          spark.databricks.cluster.profile: singleNode
#        custom_tags:
#          ResourceClass: SingleNode

    # Test the results of my Python transformation
    columns:
      - name: carat
        # Standard validation for 'grain' of Python results
        data_tests:
          - not_null
